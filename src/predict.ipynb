{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e03c0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed Pasha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16784083",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the trained model\n",
    "def load_trained_model(model_path, num_classes):\n",
    "    model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\",num_labels=num_classes,ignore_mismatched_sizes=True)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "451dd288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed Pasha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vit_processors = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d72a2146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed Pasha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([10, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Get class names from training dataset\n",
    "train_dataset = ImageFolder(root=r\"C:\\Users\\Ahmed Pasha\\OneDrive\\Desktop\\garbage\\data\\train\")\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "# Load the best model\n",
    "model = load_trained_model(r\"C:\\Users\\Ahmed Pasha\\OneDrive\\Desktop\\garbage\\src\\models\\best_vit_model.pth\", len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c8dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vit_transformers(image):\n",
    "    \"\"\"Transform function for ViT model\"\"\"\n",
    "    # Process the image using ViT processor\n",
    "    inputs = vit_processors(images=image, return_tensors=\"pt\")\n",
    "    return inputs['pixel_values'].squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea06cf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: biological\n",
      "Confidence: 0.9997 (99.97%)\n"
     ]
    }
   ],
   "source": [
    "# ==================== SINGLE IMAGE PREDICTION ====================\n",
    "def predict_single_image(image_path, model, transform, class_names):\n",
    "    # Load and transform image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(pixel_values=image_tensor)\n",
    "        logits = output.logits\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "        confidence, predicted_idx = torch.max(probabilities, 1)\n",
    "    \n",
    "    predicted_class = class_names[predicted_idx.item()]\n",
    "    confidence_score = confidence.item()\n",
    "    \n",
    "    return predicted_class, confidence_score\n",
    "\n",
    "# Example usage for single image\n",
    "single_image_path = r\"C:\\Users\\Ahmed Pasha\\OneDrive\\Desktop\\garbage\\data\\test\\biological\\biological_7.jpg\"\n",
    "predicted_class, confidence = predict_single_image(single_image_path, model, vit_transformers, class_names)\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "print(f\"Confidence: {confidence:.4f} ({confidence*100:.2f}%)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1153db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images in folder\n",
      "\n",
      "==================================================\n",
      "PREDICTION SUMMARY\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== FOLDER PREDICTION ====================\n",
    "def predict_folder(folder_path, model, transform, class_names, save_results=True):\n",
    "    \"\"\"\n",
    "    Predict classes for all images in a folder\n",
    "    \n",
    "    Args:\n",
    "        folder_path: Path to folder containing images\n",
    "        model: Trained model\n",
    "        transform: Image transformation pipeline\n",
    "        class_names: List of class names\n",
    "        save_results: Whether to save results to CSV\n",
    "    \n",
    "    Returns:\n",
    "        results: List of dictionaries with predictions\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "    \n",
    "    # Get all image files in folder\n",
    "    image_files = []\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(Path(folder_path).glob(f\"*{ext}\"))\n",
    "        image_files.extend(Path(folder_path).glob(f\"*{ext.upper()}\"))\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images in folder\")\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        try:\n",
    "            # Predict\n",
    "            predicted_class, confidence = predict_single_image(\n",
    "                str(img_path), model, transform, class_names\n",
    "            )\n",
    "            \n",
    "            result = {\n",
    "                'image_name': img_path.name,\n",
    "                'predicted_class': predicted_class,\n",
    "                'confidence': confidence\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "            print(f\"{img_path.name}: {predicted_class} ({confidence*100:.2f}%)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path.name}: {str(e)}\")\n",
    "    \n",
    "    # Save results to CSV\n",
    "    if save_results and results:\n",
    "        import pandas as pd\n",
    "        df = pd.DataFrame(results)\n",
    "        output_path = os.path.join(folder_path, \"predictions.csv\")\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"\\nâœ… Results saved to: {output_path}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage for folder\n",
    "test_folder_path = r\"C:\\Users\\Ahmed Pasha\\OneDrive\\Desktop\\garbage\\data\\test\"\n",
    "results = predict_folder(test_folder_path, model, vit_transformers, class_names)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PREDICTION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "class_counts = {}\n",
    "for result in results:\n",
    "    class_name = result['predicted_class']\n",
    "    class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"{class_name}: {count} images\")\n",
    "\n",
    "\n",
    "# ==================== BONUS: BATCH PREDICTION FOR FASTER PROCESSING ====================\n",
    "def predict_folder_batch(folder_path, model, transform, class_names, batch_size=32):\n",
    "    \"\"\"\n",
    "    Predict classes for folder images using batched processing (faster)\n",
    "    \"\"\"\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    \n",
    "    class ImageDataset(Dataset):\n",
    "        def __init__(self, image_paths, transform):\n",
    "            self.image_paths = image_paths\n",
    "            self.transform = transform\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.image_paths)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            img_path = self.image_paths[idx]\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            image_tensor = self.transform(image)\n",
    "            return image_tensor, img_path.name\n",
    "    \n",
    "    # Get all image files\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "    image_files = []\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(Path(folder_path).glob(f\"*{ext}\"))\n",
    "        image_files.extend(Path(folder_path).glob(f\"*{ext.upper()}\"))\n",
    "    \n",
    "    dataset = ImageDataset(image_files, transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    results = []\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, image_names in loader:\n",
    "            images = images.to(device)\n",
    "            output = model(pixel_values=images)\n",
    "            logits = output.logits\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "            confidences, predicted_indices = torch.max(probabilities, 1)\n",
    "            \n",
    "            for i in range(len(image_names)):\n",
    "                result = {\n",
    "                    'image_name': image_names[i],\n",
    "                    'predicted_class': class_names[predicted_indices[i].item()],\n",
    "                    'confidence': confidences[i].item()\n",
    "                }\n",
    "                results.append(result)\n",
    "                print(f\"{image_names[i]}: {result['predicted_class']} ({result['confidence']*100:.2f}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage for batch prediction (faster)\n",
    "# results_batch = predict_folder_batch(test_folder_path, model, vit_transformers, class_names, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ed5af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92323aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed0663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
