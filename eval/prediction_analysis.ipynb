{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dda226",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3605151825.py, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 34\u001b[1;36m\u001b[0m\n\u001b[1;33m    model.load_state_dict(torch.load(\"C:\\Users\\Ahmed Pasha\\OneDrive\\Desktop\\garbage\\model\\best_vit_model.pth\", map_location=device))\u001b[0m\n\u001b[1;37m                                                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# ==================== PREDICTION CONFIDENCE ANALYSIS ====================\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==================== SETUP ====================\n",
    "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "def vit_transformers(image):\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    return inputs['pixel_values'].squeeze(0)\n",
    "\n",
    "test_dataset = ImageFolder(\n",
    "    root=r\"C:\\Users\\Ahmed Pasha\\OneDrive\\Desktop\\garbage\\data\\test\",\n",
    "    transform=vit_transformers\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "class_names = test_dataset.classes\n",
    "\n",
    "# Load model\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\",\n",
    "    num_labels=len(class_names),\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model.load_state_dict(torch.load(\"C:\\Users\\Ahmed Pasha\\OneDrive\\Desktop\\garbage\\model\\best_vit_model.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ==================== GET DETAILED PREDICTIONS ====================\n",
    "def get_detailed_predictions(model, loader, dataset):\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_confidences = []\n",
    "    all_image_paths = []\n",
    "    \n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(pixel_values=images)\n",
    "            probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "            confidences, predictions = torch.max(probabilities, 1)\n",
    "            \n",
    "            batch_size = images.size(0)\n",
    "            for i in range(batch_size):\n",
    "                all_predictions.append(predictions[i].item())\n",
    "                all_labels.append(labels[i].item())\n",
    "                all_confidences.append(confidences[i].item())\n",
    "                all_image_paths.append(dataset.imgs[idx][0])\n",
    "                idx += 1\n",
    "    \n",
    "    return all_predictions, all_labels, all_confidences, all_image_paths\n",
    "\n",
    "print(\"ðŸ”„ Getting detailed predictions...\")\n",
    "predictions, labels, confidences, image_paths = get_detailed_predictions(\n",
    "    model, test_loader, test_dataset\n",
    ")\n",
    "print(\"âœ… Predictions obtained!\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "predictions = np.array(predictions)\n",
    "labels = np.array(labels)\n",
    "confidences = np.array(confidences)\n",
    "\n",
    "# Calculate correctness\n",
    "correct = predictions == labels\n",
    "\n",
    "# ==================== CONFIDENCE STATISTICS ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONFIDENCE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Mean Confidence: {np.mean(confidences):.4f}\")\n",
    "print(f\"Median Confidence: {np.median(confidences):.4f}\")\n",
    "print(f\"Std Confidence: {np.std(confidences):.4f}\")\n",
    "print(f\"Min Confidence: {np.min(confidences):.4f}\")\n",
    "print(f\"Max Confidence: {np.max(confidences):.4f}\")\n",
    "\n",
    "print(\"\\nCorrect vs Incorrect Predictions:\")\n",
    "print(f\"Mean Confidence (Correct): {np.mean(confidences[correct]):.4f}\")\n",
    "print(f\"Mean Confidence (Incorrect): {np.mean(confidences[~correct]):.4f}\")\n",
    "\n",
    "# ==================== CONFIDENCE DISTRIBUTION ====================\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(confidences[correct], bins=50, alpha=0.7, label='Correct', color='green', edgecolor='black')\n",
    "plt.hist(confidences[~correct], bins=50, alpha=0.7, label='Incorrect', color='red', edgecolor='black')\n",
    "plt.xlabel('Confidence', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Confidence Distribution', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([confidences[correct], confidences[~correct]], \n",
    "            labels=['Correct', 'Incorrect'],\n",
    "            patch_artist=True,\n",
    "            boxprops=dict(facecolor='lightblue', color='black'),\n",
    "            medianprops=dict(color='red', linewidth=2))\n",
    "plt.ylabel('Confidence', fontsize=12)\n",
    "plt.title('Confidence Box Plot', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confidence_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Confidence distribution saved to 'confidence_distribution.png'\")\n",
    "\n",
    "# ==================== CONFIDENCE BY CLASS ====================\n",
    "confidence_by_class = {class_name: [] for class_name in class_names}\n",
    "for i in range(len(predictions)):\n",
    "    pred_class = class_names[predictions[i]]\n",
    "    confidence_by_class[pred_class].append(confidences[i])\n",
    "\n",
    "mean_confidence_by_class = {k: np.mean(v) if v else 0 for k, v in confidence_by_class.items()}\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(mean_confidence_by_class.keys(), mean_confidence_by_class.values(), \n",
    "        color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Class', fontsize=12)\n",
    "plt.ylabel('Mean Confidence', fontsize=12)\n",
    "plt.title('Mean Prediction Confidence by Class', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim([0, 1.1])\n",
    "for i, (k, v) in enumerate(mean_confidence_by_class.items()):\n",
    "    plt.text(i, v + 0.02, f'{v:.3f}', ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confidence_by_class.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Confidence by class saved to 'confidence_by_class.png'\")\n",
    "\n",
    "# ==================== LOW CONFIDENCE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
