Garbage Classification using Vision Transformer (ViT)
ğŸ“Œ Project Overview

This project implements an end-to-end image classification system using a Vision Transformer (ViT) model to classify garbage images into multiple classes.
The project follows best practices, including model evaluation, testing, Dockerization, and CI/CD automation.

ğŸ¯ Objectives

Train a ViT-based image classification model

Evaluate model performance using multiple metrics

Save and reuse the trained model

Automate testing and builds using CI/CD

Provide a reproducible environment using Docker

ğŸ§  Model Information

Model Type: Vision Transformer (ViT)

Base Model: google/vit-base-patch16-224

Framework: PyTorch + HuggingFace Transformers

Saved Model Path: model/best_vit_model.pth

ğŸ“‚ Project Structure
GARBAGE/
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ ci-cd.yaml                # CI/CD pipeline configuration
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ...                       # Dataset (train / validation / test)
â”‚
â”œâ”€â”€ eval/                         # Evaluation results & notebooks
â”‚   â”œâ”€â”€ classification_report.csv
â”‚   â”œâ”€â”€ precision_recall_f1.csv
â”‚   â”œâ”€â”€ confidence_by_class.png
â”‚   â”œâ”€â”€ confidence_distribution.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ confusion_matrix_normalized.png
â”‚   â”œâ”€â”€ metrics_heatmap.png
â”‚   â”œâ”€â”€ metrics_radar.png
â”‚   â”œâ”€â”€ per_class_accuracy.png
â”‚   â”œâ”€â”€ precision_recall_f1_bars.png
â”‚   â”œâ”€â”€ test_distribution.png
â”‚   â”œâ”€â”€ cr_cm.ipynb
â”‚   â”œâ”€â”€ precision_recall.ipynb
â”‚   â””â”€â”€ prediction_analysis.ipynb
â”‚
â”œâ”€â”€ model/
â”‚   â””â”€â”€ best_vit_model.pth        # Trained ViT model
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.ipynb               # Model training notebook
â”‚   â””â”€â”€ predict.ipynb             # Model inference notebook
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_model.py             # Unit tests
â”‚
â”œâ”€â”€ Dockerfile                    # Docker configuration
â”œâ”€â”€ requirements.txt              # Project dependencies
â”œâ”€â”€ README.md                     # Project documentation
â””â”€â”€ .gitignore

ğŸ‹ï¸ Model Training

Model training is performed using the notebook:

src/train.ipynb

Training Workflow:

Load images from the data/ directory

Apply ViT image preprocessing

Fine-tune the ViT model

Save the best model to model/best_vit_model.pth

ğŸ” Model Evaluation

All evaluation artifacts are stored in the eval/ folder.

Evaluation Includes:

Accuracy (overall & per-class)

Precision, Recall, F1-score

Confusion Matrix (raw & normalized)

Confidence analysis per class

Visual reports (heatmaps, radar charts, bar plots)

ğŸ§ª Testing

Automated tests ensure model correctness.

Run Tests:
pytest


Test files are located in:

tests/test_model.py

ğŸ³ Docker Usage
Build Docker Image
docker build -t vit-garbage-classifier .

Run Docker Container
docker run vit-garbage-classifier

ğŸ”„ CI/CD Pipeline

The project uses GitHub Actions for continuous integration and delivery.

Pipeline file:

.github/workflows/ci-cd.yaml

CI/CD Tasks:

Code checkout

Dependency installation

Unit testing

Docker image build

ğŸ“¦ Local Setup
Create Virtual Environment
python -m venv venv
source venv/bin/activate      # Linux / Mac
venv\Scripts\activate         # Windows

Install Dependencies
pip install -r requirements.txt

ğŸ§° Tech Stack

Python

PyTorch

HuggingFace Transformers (ViT)

Scikit-learn

Matplotlib & Seaborn

Pytest

Docker

GitHub Actions

ğŸš€ Future Improvements

MLflow experiment tracking

DVC + DagsHub for data versioning

REST API using FastAPI

Cloud deployment (AWS / GCP / Azure)

ğŸ‘¨â€ğŸ’» Author

Ahmed Pasha
Machine Learning Engineer | MLOps Enthusias